{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+4msfYkOtwE8L0WrgASXh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katrin2202/NLP/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Работа с объектами-контейнерами и настройками spaCy под свои нужды"
      ],
      "metadata": {
        "id": "YH-ikFFI6Nr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Объекты-контейнеры бибилиотеки spaCy"
      ],
      "metadata": {
        "id": "S7r1JzRZYfVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Получение индекса токена в объекте Doc"
      ],
      "metadata": {
        "id": "nuKfutcD6bKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens.doc import Doc\n",
        "from spacy.vocab import Vocab"
      ],
      "metadata": {
        "id": "KD7DbfB068F7"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь вызываем конструктор класса `Doc` и передаем ему два параметра: объект `vocab` — контейнер хранилища со словарными данными и список токенов для добавления в создаваемый объект `Doc`"
      ],
      "metadata": {
        "id": "MR46jSpk7VFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = Doc(Vocab(), words=[u'Hi', u'there'])\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udb1rqi-6lmE",
        "outputId": "69c2e29a-4fe1-4ba8-d1ba-7384d2a53853"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Hi there "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обход в цикле синтаксических дочерних элементов токена"
      ],
      "metadata": {
        "id": "puW9vLMO7wnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нам потребуется установить и загрузать пакет обученного конвейера по умолчанию"
      ],
      "metadata": {
        "id": "0A0j1pFY9D-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-fPPY1Q82aK",
        "outputId": "9164d3c4-1d54-4527-8159-22400b8135da"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "s0uO4J2W8tgS"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для получения программным образом левосторонних дочерних элементов токена *apple* в данном предложении можно воспользоваться следующим кодом:"
      ],
      "metadata": {
        "id": "YfNehPL89LlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"I want a green apple.\")\n",
        "[w for w in doc[4].lefts]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KdepNOf7SAi",
        "outputId": "720d9c59-6f58-451e-a2b3-16bd0be0150f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[a, green]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "У слова *apple* есть только левосторонние синтаксические дочерние элементы. На практике это означает, что можно заменить атрибут `Token.lefts` на `Token.children`, служащий для поиска всех дочерних элементов токена:"
      ],
      "metadata": {
        "id": "JTyIp8fo9mIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[w for w in doc[4].children]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAeMb29677IC",
        "outputId": "12ac00f7-e820-4f00-dff6-0ecb13d565ec"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[a, green]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно также использовать атрибут `Token.rights` для получения правосторонних синтаксических дочерних элементов:\n",
        "Но слово *apply* само является правосторонним дочерним элементом слова want"
      ],
      "metadata": {
        "id": "dRl7SR4j90BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[w for w in doc[4].rights]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfxHLeqo9sOn",
        "outputId": "f1c9784a-31d6-450b-b49f-a78ab8b33e91"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Контейнер `doc.sents`"
      ],
      "metadata": {
        "id": "Q-9L6S4l-IAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cмысл синтаксических меток, присваиваемых токенам, проявляется лишь в контексте предложения, где встречается данный токен.\n",
        "С помощью свойства `doc.sents` объекта `Doc` текст можно разделить на отдельные предложения, как показано в следующем примере:"
      ],
      "metadata": {
        "id": "ZRNTszLW-SXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь проходим по предложениям из объекта `doc`, создавая отдельный список токенов для каждого предложения"
      ],
      "metadata": {
        "id": "TAJj4jdL-lYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u'A severe storm hit the beach. It started to rain.')\n",
        "for sent in doc.sents:\n",
        "  print([sent[i] for i in range(len(sent))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lef28Fta95Fp",
        "outputId": "43cfe8bf-45e2-461d-f3ab-5d67431dc547"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[A, severe, storm, hit, the, beach, .]\n",
            "[It, started, to, rain, .]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В то же время можно ссылаться на токены в состоящем из множества предложений тексте с помощью глобальных индексов уровня документа, как показано вот здесь:"
      ],
      "metadata": {
        "id": "KVTLtlUE-sDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[doc[i] for i in range(len(doc))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYoDKSAh-dmp",
        "outputId": "2e509af8-97d0-4f0b-e277-739ebbd3f156"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[A, severe, storm, hit, the, beach, ., It, started, to, rain, .]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возможность ссылаться на объекты `Token` в документе по их индексам уровня предложения удобна, когда нужно, например, проверить, является ли первое слово во втором предложении обрабатываемого текста местоимением"
      ],
      "metadata": {
        "id": "9D-qfAxv-0kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i,sent in enumerate(doc.sents):\n",
        "  if i==1 and sent[0].pos_== 'PRON':\n",
        "    print('The second sentence begins with a pronoun.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQwSEzMI-vTo",
        "outputId": "eaff78f9-7201-45c4-ca20-ef8f5933e7ab"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The second sentence begins with a pronoun.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выбор первого слова в предложении — элементарная задача, поскольку его индекс всегда равен 0. А как насчет последнего? Например, что делать, если необходимо определить, сколько предложений в тексте оканчивается глаголом (не считая точек и прочих знаков препинания)?"
      ],
      "metadata": {
        "id": "HCVlgl8m_CyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Хотя длины предложений различны, их можно легко вычислить с помощью функции `len()`. Вычитаем 2 из значения `len(sent)` по следующим причинам: во-первых, индексы всегда начинаются с 0 и заканчиваются на *size-1*, во-вторых, последний токен в обоих предложениях нашего примера текста — точка, которую не нужно учитывать."
      ],
      "metadata": {
        "id": "2OB1O1DT_PxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "for sent in doc.sents:\n",
        "  if sent[len(sent)-2].pos_ == 'VERB':\n",
        "    counter+=1\n",
        "print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQYcC31T-6g3",
        "outputId": "54b5971f-d30f-480d-9850-53d5a5c4f2e4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Контейнер `doc.noun_chunks`"
      ],
      "metadata": {
        "id": "U1VOz7Bx_cEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью свойства `doc.noun_chunks` объекта `Doc` можно пройти по именным фрагментам. Именной фрагмент (*noun chunk*) — это фраза, главным элементом которой является существительное."
      ],
      "metadata": {
        "id": "f2wacGlE_iKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u'A noun chunk is a phrase that has a noun as its head.')\n",
        "for chunk in doc.noun_chunks:\n",
        "  print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjB3lsEg_KlZ",
        "outputId": "565093bc-4393-49a1-fa32-927372c7f702"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A noun chunk\n",
            "a phrase\n",
            "that\n",
            "a noun\n",
            "its head\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Или же для извлечения именных фрагментов можно обойти в цикле существительные в предложении и найти синтаксические дочерние элементы каждого существительного, чтобы из них образовать именные фрагменты."
      ],
      "metadata": {
        "id": "moK7U90n_xYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  if token.pos_=='NOUN':\n",
        "    chunk = ''\n",
        "    for w in token.children:\n",
        "       if w.pos_ == 'DET' or w.pos_ == 'ADJ':\n",
        "         chunk = chunk + w.text + ' '\n",
        "    chunk = chunk + token.text\n",
        "    print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBkb6_X7_tED",
        "outputId": "333926e5-faba-4055-8d71-37f391321386"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noun\n",
            "A chunk\n",
            "a phrase\n",
            "a noun\n",
            "head\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Объект Span"
      ],
      "metadata": {
        "id": "5NCKy-61PJHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объект *Span* (от англ. span — «интервал») представляет собой часть объекта `Doc`."
      ],
      "metadata": {
        "id": "B8COShR6PMG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp('I want a green apple.')\n",
        "doc[2:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhcbGUJs_6PO",
        "outputId": "7a687245-f218-4445-e0e4-015ece520827"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "a green apple"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объект Span включает несколько методов, самый интересный из которых — `span.merge()`. С его помощью интервал можно объединять в единый токен, производя повторную токенизацию документа."
      ],
      "metadata": {
        "id": "Omj1ZBejPfXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u'The Golden Gate Bridge is an iconic landmark in San Francisco.')\n",
        "[doc[i] for i in range(len(doc))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUExFTyvBDD1",
        "outputId": "4890fa5b-0e76-4a7f-d7ec-01b36a5c0674"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[The, Golden, Gate, Bridge, is, an, iconic, landmark, in, San, Francisco, .]"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Каждому слову и знаку препинания соответствует отдельный токен.\n",
        "\n",
        "С помощью метода `span.merge()` можно изменить поведение по умолчанию:"
      ],
      "metadata": {
        "id": "rcuIzj-sP3pb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Поправка *Spacy* отказался от этого `span.merge()`метода с тех пор, как был создан этот учебник. Сейчас это можно сделать с помощью `doc.retokenize()`: https://spacy.io/api/doc#retokenize . \n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NjJtD0IFULWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with doc.retokenize() as retokenizer:\n",
        "  attrs = {\"LEMMA\": \"Golden Gate Bridge\"}\n",
        "  retokenizer.merge(doc[1:4], attrs=attrs)\n",
        "with doc.retokenize() as retokenizer:\n",
        "  attrs = {\"LEMMA\": \"San Francisco\"}\n",
        "  retokenizer.merge(doc[7:9], attrs=attrs)\n",
        "[doc[i] for i in range(len(doc))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO67pzfXP0j7",
        "outputId": "d1a4c7bd-1d7c-4e9d-d34b-a300dfde4cf8"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[The, Golden Gate Bridge, is, an, iconic, landmark, in, San Francisco, .]"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(\"{:<18}\\t{:<18}\\t{:<5}\\t{:<5}\".format(token.text, token.lemma_, token.pos_, token.dep_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm-o3UBgP9rv",
        "outputId": "bae7fd2f-56b9-49f3-d92d-da3e0b8df556"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The               \tthe               \tDET  \tdet  \n",
            "Golden Gate Bridge\tGolden Gate Bridge\tPROPN\tnsubj\n",
            "is                \tbe                \tAUX  \tROOT \n",
            "an                \tan                \tDET  \tdet  \n",
            "iconic            \ticonic            \tADJ  \tamod \n",
            "landmark          \tlandmark          \tNOUN \tattr \n",
            "in                \tin                \tADP  \tprep \n",
            "San Francisco     \tSan Francisco     \tPROPN\tpobj \n",
            ".                 \t.                 \tPUNCT\tpunct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Настройка конвейера обработки текста под свои нужды"
      ],
      "metadata": {
        "id": "1j-1OPzXYGwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотреть доступные для объекта `nlp` компоненты конвейера можно с помощью команды:"
      ],
      "metadata": {
        "id": "H_xoqdtdYT_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMZKk5oLRvfX",
        "outputId": "0fccc18e-af37-498e-d6ca-25b8f30dfe77"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Отключение компонентов конвейера"
      ],
      "metadata": {
        "id": "o5RH_y7TY9ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['parser'])"
      ],
      "metadata": {
        "id": "xRWAQ4UcYW2d"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном случае мы создадим конвейер обработки без утилиты разбора зависимостей. При вызове такого экземпляра `nlp` для конкретного текста токены в этом тексте не получат метки зависимостей."
      ],
      "metadata": {
        "id": "3o6KdJIvZX-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u'I want a green apple.')\n",
        "for token in doc:\n",
        "  print(\"{:<6}\\t{:<6}\\t{:<5}\".format(token.text, token.pos_, token.dep_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRPBzz23Zcb-",
        "outputId": "d902bed2-ad72-452f-acab-adaaaaa4df65"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I     \tPRON  \t     \n",
            "want  \tVERB  \t     \n",
            "a     \tDET   \t     \n",
            "green \tADJ   \t     \n",
            "apple \tNOUN  \t     \n",
            ".     \tPUNCT \t     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Пошаговая загрузка модели"
      ],
      "metadata": {
        "id": "dlYg7u1NZzC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "fvJ-IjK8Zd7U"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можете выяснить, где именно модель находится в вашей системе. Поможет вспомогательная функция `get_package_path`:"
      ],
      "metadata": {
        "id": "y5UjplhIaJcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import util\n",
        "util.get_package_path('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxVdPiUDZ4Mx",
        "outputId": "55185cb8-f814-4fab-ed6e-a887a07903ff"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/usr/local/lib/python3.7/dist-packages/en_core_web_sm')"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим модель и версию"
      ],
      "metadata": {
        "id": "EEStr2UVaans"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp.meta['lang'] + '_' + nlp.meta['name'] + '-' + nlp.meta['version'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxWwNuehaIRY",
        "outputId": "a8d7701b-648c-49c6-b823-a59d4bafd480"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en_core_web_sm-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Иногда полезно взглянуть на список компонентов конвейера, используемых с моделью. Список можно получить из поля `pipeline` атрибута `nlp.meta`"
      ],
      "metadata": {
        "id": "fIuxO5xhai9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.meta['pipeline']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aPXn3rYaXUL",
        "outputId": "81764e7f-f7e2-4542-c9d6-6462f337ba6c"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*код не работает*"
      ],
      "metadata": {
        "id": "rQFWpwOnil6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lang = 'en'\n",
        "pipeline = ['tagger', 'parser', 'ner']\n",
        "model_data_path = '/usr/local/lib/python3.7/dist-packages/en_core_web_sm-3.4.0'\n",
        "lang_cls = spacy.util.get_lang_class(lang)\n",
        "nlp = lang_cls()\n",
        "for name in pipeline:\n",
        "  # component = nlp.create_pipe(name)\n",
        "  nlp.add_pipe(name, name = name)\n",
        "nlp.from_disk(model_data_path, exclude=pipeline)"
      ],
      "metadata": {
        "id": "2WJs6PfPbfOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Настройка компонентов конвейера под свои нужды"
      ],
      "metadata": {
        "id": "KEHfNKdIdnKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u'I need a taxi to Festy.')\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70slBvjWcEVu",
        "outputId": "7d55ebe4-5aae-4b12-9c9b-2416acdf9abc"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Festy WORK_OF_ART\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метка `WORK_OF_AR` обозначает произведение искусства. Но нам нужно, чтобы средство распознавания сущностей классифицировало его как сущность типа `DISTRICT`.\n",
        "\n",
        "Сначала добавим новую метку `DISTRICT` в список поддерживаемых типов сущностей."
      ],
      "metadata": {
        "id": "6X00AYtqeLni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL = 'DISTRICT'\n",
        "TRAIN_DATA = [\n",
        "    ('We need to deliver it to Festy.', {\n",
        "        'entities': [(25, 30, 'DISTRICT')]\n",
        "    }),\n",
        "    ('I like red oranges', {\n",
        "        'entities': []\n",
        "    })\n",
        "  ]"
      ],
      "metadata": {
        "id": "HDQYVsefduzY"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Следующий этап — добавление новой метки сущности `DISTRICT` в компонент распознавания сущностей."
      ],
      "metadata": {
        "id": "zPDqhXFze5IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner = nlp.get_pipe('ner')"
      ],
      "metadata": {
        "id": "FkZsKz0re8BJ"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполнив этот шаг, в полученный объект `ner` можно добавить новую метку с помощью метода `ner.add_label()`:"
      ],
      "metadata": {
        "id": "EP0DgBpje_LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner.add_label(LABEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWx3Q8bte9Zh",
        "outputId": "5e8d111d-4571-4cb7-d72d-bbfd954935bd"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прежде чем приступить к обучению средства распознавания сущностей, необходимо отключить остальные конвейеры, чтобы во время обучения обновлялся только компонент распознавания сущностей:"
      ],
      "metadata": {
        "id": "7FEF5AFFfFWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.disable_pipes('tagger')\n",
        "nlp.disable_pipes('parser')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI6WKiPVfCv0",
        "outputId": "5a2d9438-e00f-4219-b2f3-4756bc953f3d"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['parser']"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь можно начинать обучение компонента распознаванию сущностей на примерах данных из списка `TRAIN_DATA`, который был создан ранее в этом разделе:"
      ],
      "metadata": {
        "id": "fm8DNBE9fKId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*код исправлен*"
      ],
      "metadata": {
        "id": "X3iQI4qSigbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = nlp.create_optimizer()\n",
        "import random\n",
        "from spacy.training.example import Example\n",
        "for i in range(25):\n",
        "  random.shuffle(TRAIN_DATA)\n",
        "  for text, annotations in TRAIN_DATA:\n",
        "    example = Example.from_dict(doc, annotations)\n",
        "    nlp.update([example], sgd=optimizer)"
      ],
      "metadata": {
        "id": "fvJrIHuFfIEw"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "По завершении выполнения можно проверить, как обновленный оптимизатор распознает токен Festy:"
      ],
      "metadata": {
        "id": "7IZr4XDIi2zs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*не вышло*"
      ],
      "metadata": {
        "id": "Y0lk1v03jE-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u'I need a taxi to Festy.')\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw3T_85CfP6J",
        "outputId": "c4718ed5-a046-475a-d31a-81d9d279548f"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Festy WORK_OF_ART\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь при необходимости можно загрузить обновленный компонент в новом сеансе, используя метод from_disk(). Чтобы убедиться в этом, закройте текущий сеанс интерпретатора, откройте новый и выполните следующий код:\n",
        "\n",
        "\n",
        "*не работает*"
      ],
      "metadata": {
        "id": "PvD-TXIej6PS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner.to_disk('/usr/to/ner')"
      ],
      "metadata": {
        "id": "6FxCY5egkan5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.pipeline import EntityRecognizer\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
        "ner = EntityRecognizer(nlp.vocab)\n",
        "ner.from_disk('/usr/to/ner')\n",
        "nlp.add_pipe(ner)"
      ],
      "metadata": {
        "id": "o0fB6xssjKyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u'We need to deliver it to Festy.')\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSKvdxE4jWLs",
        "outputId": "3eeb5028-c17b-4fef-ea1b-873c0aa719e0"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Festy WORK_OF_ART\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Использование структур данных уровня языка С библиотеки spaCy"
      ],
      "metadata": {
        "id": "cMtvYBA3ky3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Подготовка рабочей среды и получение текстовых файлов"
      ],
      "metadata": {
        "id": "_d5jSP8fk8BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Cython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-uT18rFksJp",
        "outputId": "020dcbcc-71fc-4334-c7b5-4c12af10c2e6"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (0.29.32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Сценарий Cypthon"
      ],
      "metadata": {
        "id": "EvydKp3TlI_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем в одном из каталогов локальной файловой системы файл `spacytext.pyx` и вставляем в него следующий код:"
      ],
      "metadata": {
        "id": "ZgJL6jEAlPz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('spacytext.pyx', 'w')"
      ],
      "metadata": {
        "id": "S62lmv-PpGwm"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f.write(\"\"\"from cymem.cymem cimport Pool\n",
        "from spacy.tokens.doc cimport Doc\n",
        "from spacy.structs cimport TokenC\n",
        "from spacy.typedefs cimport hash_t\n",
        "\n",
        "cdef struct DocStruct:\n",
        "  TokenC* c\n",
        "  int length\n",
        "\n",
        "cdef int counter(DocStruct* doc, hash_t tag):\n",
        "  cdef int cnt = 0\n",
        "  for c in doc.c[:doc.length]:\n",
        "    if c.tag == tag:\n",
        "      cnt += 1\n",
        "  return cnt\n",
        "\n",
        "cpdef main(Doc mydoc):\n",
        "  cdef int cnt\n",
        "  cdef Pool mem = Pool()\n",
        "  cdef DocStruct* doc_ptr = <DocStruct*>mem.alloc(1, sizeof(DocStruct))\n",
        "  doc_ptr.c = mydoc.c\n",
        "  doc_ptr.length = mydoc.length\n",
        "  tag = mydoc.vocab.strings.add('PRP')\n",
        "  cnt = counter(doc_ptr, tag)\n",
        "  print(doc_ptr.length)\n",
        "  print(cnt)\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMeh10gklC10",
        "outputId": "99897862-6e15-4e03-f460-b943adde46db"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "623"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f.close()"
      ],
      "metadata": {
        "id": "17QqlKdwpZoe"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Сборка модуля Cython"
      ],
      "metadata": {
        "id": "NDZwHdo6oiLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем файл `setup.py` в каталоге, где располагается наш сценарий Cython. Файл должен содержать следующий код:"
      ],
      "metadata": {
        "id": "JzQ0hK8-qOe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('setup.py', 'w')"
      ],
      "metadata": {
        "id": "Iy90a6fyqSHd"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f.write('''from distutils.core import setup\n",
        "from Cython.Build import cythonize\n",
        "\n",
        "import numpy\n",
        "setup(name='spacy text app',\n",
        "      ext_modules=cythonize(\"spacytext.pyx\", language=\"c++\"),\n",
        "      include_dirs=[numpy.get_include()]\n",
        "      )''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2s0_gJ1oflf",
        "outputId": "14249f9e-698a-4540-921c-4642b57805ad"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f.close()"
      ],
      "metadata": {
        "id": "R_Rm6qDlofiY"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "После подготовки установочного сценария компилируем код Cython.\n",
        "Сделать это можно из системного терминала:"
      ],
      "metadata": {
        "id": "V2_cxToSqkoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py build_ext --inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOpympwSqiv6",
        "outputId": "30d04c98-c4dc-438f-a26d-877724300b61"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: passing language='c++' to cythonize() is deprecated. Instead, put \"# distutils: language=c++\" in your .pyx or .pxd file(s)\n",
            "running build_ext\n",
            "building 'spacytext' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-cpython-37\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c spacytext.cpp -o build/temp.linux-x86_64-cpython-37/spacytext.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1969:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kspacytext.cpp:774\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-cpython-37\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-37/spacytext.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-37/spacytext.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-cpython-37/spacytext.cpython-37m-x86_64-linux-gnu.so -> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Тестирование модуля"
      ],
      "metadata": {
        "id": "ZjXSp8tUqnuV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "После успешного завершения процесса компиляции модуль `spacytext` будет добавлен в среду Python. Для его тестирования откройте сеанс Python и выполните команду:"
      ],
      "metadata": {
        "id": "0HCePGOQqy8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacytext import main"
      ],
      "metadata": {
        "id": "kcbPebJoqrPs"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "f= open(\"test.txt\",\"rb\")\n",
        "contents =f.read()\n",
        "doc = nlp(contents[:100000].decode('utf8'))\n",
        "main(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YjtLGDAq5_d",
        "outputId": "5845ed3d-1f02-4ac9-da3a-3d1fe1ab7bac"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Выделение и использование лингвистических признаков"
      ],
      "metadata": {
        "id": "UdaVFcADsVF3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0K1G4xKFq9Z2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}